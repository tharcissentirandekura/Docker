{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tharcissentirandekura/Docker/blob/main/langchain_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Chatbot Tutorial ü§ñ\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Welcome to this beginner-friendly tutorial on building a chatbot with LangChain and LangGraph!\n",
        "\n",
        "## What you'll learn:\n",
        "- How to set up a simple AI chatbot\n",
        "- Understanding the basic components of LangChain/LangGraph\n",
        "- How to interact with Google's Gemini AI model\n",
        "- Building a conversational flow\n",
        "\n",
        "## Prerequisites:\n",
        "- No prior Python knowledge required! We'll explain everything step by step\n",
        "- A Google API key (we'll show you how to get one)\n",
        "\n",
        "Let's get started! üöÄ\n"
      ],
      "metadata": {
        "id": "RGmAQeZuQArO"
      }
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "osEQKHmZMJfn"
      },
      "source": [
        "Step 1: Getting Your Google API Key üîë\n",
        "\n",
        "Before we start coding, you'll need a Google API key to use the Gemini AI model.\n",
        "\n",
        "How to get your API key:\n",
        "1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)\n",
        "2. Sign in with your Google account\n",
        "3. Click \"Create API Key\"\n",
        "4. Copy the key (keep it safe!)\n",
        "\n",
        "Important Notes:\n",
        "- ‚ö†Ô∏è **Never share your API key publicly**\n",
        "- ‚ö†Ô∏è **Don't commit it to GitHub or other public repositories**\n",
        "- üí° **Tip**: You can use Google AI Studio for free with rate limits\n",
        "\n",
        "Once you have your key, we'll show you how to use it safely!\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "Hl3foULiMJfo"
      },
      "source": [
        "Step 2: Install Required Packages üì¶\n",
        "\n",
        "First, we need to install the packages that our chatbot will use. Think of these as tools in a toolbox - each one has a specific job!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IPCv51uxMJfo",
        "outputId": "a54a1404-4a00-4c06-c185-d5ce031532b1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.13-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (3.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "INFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "INFO: pip is still looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pip>=25.2 (from langchain-text-splitters<1.0.0,>=0.3.9->langchain)\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.12-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.11-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading langchain_tavily-0.2.10-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading langchain_tavily-0.2.9-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.8-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.7-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.6-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.5-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.4-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting mypy<2.0.0,>=1.15.0 (from langchain-tavily)\n",
            "  Downloading mypy-1.18.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.3-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.2-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.1-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading langchain_tavily-0.1.6-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading langchain_tavily-0.1.5-py3-none-any.whl.metadata (11 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.8.5)\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-2.0.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading langchain_google_genai-2.0.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading langchain_google_genai-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.6-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting google-generativeai<0.6.0,>=0.5.2 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.5-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting google-generativeai<0.5.0,>=0.4.1 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-0.0.11-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-0.0.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting google-generativeai<0.4.0,>=0.3.1 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-0.0.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_google_genai-0.0.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_google_genai-0.0.6-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-0.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-0.0.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-0.0.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_google_genai-0.0.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "  Downloading langchain_google_genai-0.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_tavily-0.2.13-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, ormsgpack, langgraph-sdk, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langgraph, langchain-tavily\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.9.0 langchain-google-genai-2.1.12 langchain-tavily-0.2.13 langgraph-1.0.1 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 ormsgpack-1.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "64e47c5200f54edeacfe0e96fc036044"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Installation complete! Ready to build our chatbot.\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "# This might take a few minutes the first time you run it\n",
        "\n",
        "%pip install langchain langgraph langchain-google-genai langchain-tavily\n",
        "\n",
        "print(\"‚úÖ Installation complete! Ready to build our chatbot.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "aRicUAstMJfp"
      },
      "source": [
        "Step 3: Set Up Your API Key üîê\n",
        "\n",
        "Now we'll set up your Google API key. Replace `\"your_api_key_here\"` with the actual key you got from Google AI Studio.\n",
        "\n",
        "**Important**: This is just for learning purposes. In a real application, you'd store this more securely!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWze2cNpMJfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f150dafb-779f-4e2d-d053-0b345958c23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API key is set up!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Replace \"your_api_key_here\" with your actual Google API key\n",
        "# Make sure to keep the quotes around it!\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"your_api_key_here\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "\n",
        "# This line checks if the key was set correctly\n",
        "if os.environ.get(\"GOOGLE_API_KEY\") == \"your_api_key_here\":\n",
        "    print(\"‚ö†Ô∏è  Don't forget to replace 'your_api_key_here' with your actual API key!\")\n",
        "else:\n",
        "    print(\"‚úÖ API key is set up!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "DbyTqQ7PMJfp"
      },
      "source": [
        "Step 4: Import the Tools We Need üõ†Ô∏è\n",
        "\n",
        "Now let's import all the tools (libraries) we'll use to build our chatbot. Think of this like gathering all your ingredients before cooking!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_0sm8kTMJfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc686e4-ea70-429c-c256-48a5a337039d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All tools imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import statements - these bring in the tools we need\n",
        "from typing import Annotated                      # Helps with type hints (optional but good practice)\n",
        "from typing_extensions import TypedDict           # Helps us define data structures\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END    # The main graph components\n",
        "from langgraph.graph.message import add_messages      # Handles message management\n",
        "from langchain.chat_models import init_chat_model     # Connects to AI models\n",
        "\n",
        "print(\"‚úÖ All tools imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "kS8Xp6dZMJfq"
      },
      "source": [
        "Step 5: Define the State Structure üìã\n",
        "\n",
        "In LangGraph, we need to define what information our chatbot will keep track of. Think of this as the chatbot's \"memory\" structure.\n",
        "\n",
        "For our chatbot, we only need to remember the conversation messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU0KS3GFMJfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7e87be-3843-40c9-982e-9d76100cd513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ State structure defined!\n",
            "Our chatbot will remember: messages in the conversation\n"
          ]
        }
      ],
      "source": [
        "# Define what our chatbot will remember\n",
        "class State(TypedDict):\n",
        "    # This stores all the messages in our conversation\n",
        "    # The `add_messages` part tells LangGraph to add new messages to the list\n",
        "    # instead of replacing the whole list\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "print(\"‚úÖ State structure defined!\")\n",
        "print(\"Our chatbot will remember: messages in the conversation\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "WfNfQs5iMJfr"
      },
      "source": [
        "## Step 6: Connect to the AI Model üß†\n",
        "\n",
        "Now we'll connect to Google's Gemini AI model. This is the \"brain\" that will generate responses to user messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHDXETf3MJfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb28fcf-74b8-415f-bb01-977a23504341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Connected to Gemini AI!\n",
            "Model: gemini-2.0-flash\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google's Gemini AI model\n",
        "# \"gemini-2.0-flash\" is a fast and capable version of Google's AI\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n",
        "\n",
        "print(\"‚úÖ Connected to Gemini AI!\")\n",
        "print(\"Model: gemini-2.0-flash\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "hwFtRv7ZMJfr"
      },
      "source": [
        "Step 7: Create the Chatbot Function üí¨\n",
        "\n",
        "Now we'll create the main function that handles conversations. This function takes the current state (all previous messages) and generates a new response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biGScGHaMJfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf39af4-ae7c-4084-e63e-81d273944c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Chatbot function created!\n",
            "This function will process messages and generate AI responses.\n"
          ]
        }
      ],
      "source": [
        "# This function is the \"brain\" of our chatbot\n",
        "def chatbot(state: State):\n",
        "    \"\"\"\n",
        "    This function takes the conversation history and generates a response.\n",
        "\n",
        "    How it works:\n",
        "    1. Takes all the messages from the conversation so far\n",
        "    2. Sends them to the AI model (Gemini)\n",
        "    3. Gets back a response\n",
        "    4. Returns the response in the format LangGraph expects\n",
        "    \"\"\"\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"‚úÖ Chatbot function created!\")\n",
        "print(\"This function will process messages and generate AI responses.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "aKxjBwGHMJfs"
      },
      "source": [
        "## Step 8: Build the Conversation Graph üîó\n",
        "\n",
        "LangGraph uses a \"graph\" to define how conversations flow. Think of it like a flowchart:\n",
        "- START ‚Üí Our chatbot function ‚Üí END\n",
        "\n",
        "This creates a simple back-and-forth conversation pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmAB57QtMJfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf81ecf0-6814-41af-b8e8-adb49ba2df3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Conversation graph built!\n",
            "Flow: START ‚Üí chatbot function ‚Üí END\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create a graph builder\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Step 2: Add our chatbot function as a \"node\" in the graph\n",
        "# The first part (\"chatbot\") is just a name we give it\n",
        "# The second part (chatbot) is our actual function\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Step 3: Define the flow: START ‚Üí chatbot ‚Üí END\n",
        "graph_builder.add_edge(START, \"chatbot\")  # When conversation starts, go to chatbot\n",
        "graph_builder.add_edge(\"chatbot\", END)    # After chatbot responds, end this turn\n",
        "\n",
        "# Step 4: Build the final graph\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "print(\"‚úÖ Conversation graph built!\")\n",
        "print(\"Flow: START ‚Üí chatbot function ‚Üí END\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "N7Tb_f1uMJfs"
      },
      "source": [
        "Step 9: Test Your Chatbot! üéâ\n",
        "\n",
        "Now let's test our chatbot with a simple message. This function will send a message and show the response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dXYEhipMJfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfd45e5-8c75-4807-c0bc-427975f42328",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: How can I get better at building AI agents?\n",
            "Assistant: Getting better at building AI agents is a multifaceted process that requires a combination of theoretical knowledge, practical experience, and continuous learning. Here's a breakdown of how you can improve your skills:\n",
            "\n",
            "**1. Foundational Knowledge:**\n",
            "\n",
            "*   **Programming Fundamentals:**\n",
            "    *   **Python:** This is the most popular language for AI due to its extensive libraries and readability. Master its core concepts, data structures, and object-oriented programming principles.\n",
            "    *   **Other Languages (Optional):**  C++ is useful for performance-critical applications.  Java can be used for enterprise-level AI.\n",
            "*   **Mathematics:**\n",
            "    *   **Linear Algebra:**  Essential for understanding machine learning algorithms, especially neural networks.  Focus on vectors, matrices, and their operations.\n",
            "    *   **Calculus:**  Understanding derivatives and gradients is crucial for optimization algorithms like gradient descent.\n",
            "    *   **Probability and Statistics:**  Fundamental for understanding data distributions, hypothesis testing, and Bayesian methods.\n",
            "*   **Artificial Intelligence Concepts:**\n",
            "    *   **Search Algorithms:**  Understand algorithms like A*, Dijkstra's algorithm, and Monte Carlo Tree Search (MCTS) for problem-solving and game playing.\n",
            "    *   **Planning:**  Learn about planning algorithms like STRIPS and PDDL for creating sequences of actions to achieve goals.\n",
            "    *   **Reinforcement Learning (RL):**  A key area for building autonomous agents that learn from experience. Understand concepts like Markov Decision Processes (MDPs), Q-learning, Deep Q-Networks (DQNs), Policy Gradients, and Actor-Critic methods.\n",
            "    *   **Machine Learning (ML):**  While not all agents rely on ML, it's often crucial. Understand supervised learning (classification, regression), unsupervised learning (clustering, dimensionality reduction), and semi-supervised learning.\n",
            "    *   **Natural Language Processing (NLP):**  If your agent needs to understand or generate human language, NLP is essential.  Learn about techniques like tokenization, part-of-speech tagging, named entity recognition, sentiment analysis, and language modeling.\n",
            "*   **Data Structures and Algorithms:**  Strong knowledge of these will help you write efficient and scalable code.\n",
            "\n",
            "**2. Tools and Libraries:**\n",
            "\n",
            "*   **Python Libraries:**\n",
            "    *   **NumPy:**  For numerical computation and array manipulation.\n",
            "    *   **Pandas:**  For data analysis and manipulation (dataframes).\n",
            "    *   **Scikit-learn:**  A comprehensive machine learning library with a wide range of algorithms.\n",
            "    *   **TensorFlow/Keras:**  Powerful libraries for deep learning. Keras provides a high-level API for building neural networks on top of TensorFlow.\n",
            "    *   **PyTorch:**  Another popular deep learning library, known for its flexibility and dynamic computation graph.\n",
            "    *   **OpenAI Gym/Farama Gymnasium:**  Environments for developing and testing reinforcement learning agents.\n",
            "    *   **NLTK/SpaCy:**  Libraries for natural language processing.\n",
            "    *   **Ray/Dask:** Distributed computing frameworks for scaling up AI agent training and deployment.\n",
            "*   **Development Environments:**\n",
            "    *   **Jupyter Notebooks/JupyterLab:**  Interactive environments for coding and experimenting.\n",
            "    *   **VS Code/PyCharm:**  Powerful IDEs for software development.\n",
            "*   **Version Control:**\n",
            "    *   **Git:**  Essential for managing your code and collaborating with others.  Use platforms like GitHub or GitLab.\n",
            "\n",
            "**3. Practical Experience:**\n",
            "\n",
            "*   **Start with Simple Projects:**\n",
            "    *   **Rule-Based Agents:**  Implement a simple agent that follows a set of predefined rules to achieve a goal.  Examples: a simple chatbot, a tic-tac-toe player.\n",
            "    *   **Search-Based Agents:**  Implement an agent that uses search algorithms (e.g., A*) to find a solution to a problem. Examples: a pathfinding agent, a puzzle solver.\n",
            "*   **Move to More Complex Projects:**\n",
            "    *   **Reinforcement Learning Agents:**  Train an agent to play a game (e.g., Atari games, board games) using RL algorithms.  Start with simple environments and gradually increase the complexity.\n",
            "    *   **NLP-Based Agents:**  Build a chatbot that can understand and respond to user queries.  Use pre-trained language models and fine-tune them for specific tasks.\n",
            "    *   **Hybrid Agents:**  Combine different AI techniques to create more sophisticated agents.  For example, an agent that uses both RL and planning.\n",
            "*   **Contribute to Open Source Projects:**  This is a great way to learn from experienced developers and contribute to the AI community.\n",
            "*   **Participate in Competitions:**  Platforms like Kaggle and AIcrowd host competitions that challenge you to build AI agents for various tasks. This provides valuable experience and exposure to different problem domains.\n",
            "*   **Implement Existing Algorithms from Scratch:**  This forces you to deeply understand the underlying principles.\n",
            "\n",
            "**4. Learning Resources:**\n",
            "\n",
            "*   **Online Courses:**\n",
            "    *   **Coursera:**  Offers courses on AI, machine learning, deep learning, and reinforcement learning from top universities.\n",
            "    *   **edX:**  Similar to Coursera, with courses from leading institutions.\n",
            "    *   **Udacity:**  Offers nanodegree programs in AI and related fields.\n",
            "    *   **Fast.ai:**  Provides practical deep learning courses.\n",
            "    *   **Deeplearning.ai:**  Specialized courses on deep learning.\n",
            "    *   **MIT OpenCourseware:**  Free access to course materials from MIT, including AI and machine learning.\n",
            "*   **Books:**\n",
            "    *   **\"Artificial Intelligence: A Modern Approach\" by Stuart Russell and Peter Norvig:**  A comprehensive textbook on AI.\n",
            "    *   **\"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto:**  A classic textbook on reinforcement learning.\n",
            "    *   **\"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" by Aur√©lien G√©ron:**  A practical guide to machine learning with Python.\n",
            "    *   **\"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville:**  A comprehensive textbook on deep learning.\n",
            "*   **Research Papers:**  Stay up-to-date with the latest research in AI by reading papers from conferences like NeurIPS, ICML, ICLR, and AAAI.  ArXiv is a good place to find preprints.\n",
            "*   **Blogs and Websites:**\n",
            "    *   **Towards Data Science:**  A popular blog with articles on data science and AI.\n",
            "    *   **Machine Learning Mastery:**  A website with tutorials and resources on machine learning.\n",
            "    *   **Distill:**  Publishes interactive explanations of AI concepts.\n",
            "    *   **OpenAI Blog:**  Updates on OpenAI's research and projects.\n",
            "    *   **Google AI Blog:**  Updates on Google's AI research and projects.\n",
            "*   **Communities:**\n",
            "    *   **Stack Overflow:**  A great resource for getting help with coding problems.\n",
            "    *   **Reddit (r/MachineLearning, r/artificialintelligence):**  Online communities for discussing AI topics.\n",
            "    *   **Discord Servers:** Many AI communities have active Discord servers.\n",
            "\n",
            "**5. Key Skills to Develop:**\n",
            "\n",
            "*   **Problem Decomposition:** Breaking down complex problems into smaller, manageable subproblems.\n",
            "*   **Algorithm Design:** Choosing and adapting appropriate algorithms for the task.\n",
            "*   **Data Analysis:**  Understanding and preparing data for training.\n",
            "*   **Model Evaluation:**  Evaluating the performance of your agent and identifying areas for improvement.\n",
            "*   **Debugging:**  Identifying and fixing errors in your code.\n",
            "*   **Experimentation:**  Trying different approaches and evaluating their effectiveness.\n",
            "*   **Communication:**  Clearly explaining your work and collaborating with others.\n",
            "\n",
            "**6.  Specific Areas to Focus On (Depending on Your Interests):**\n",
            "\n",
            "*   **Game Playing:**  If you're interested in building agents that play games, focus on reinforcement learning, search algorithms, and game theory.  Consider libraries like Pygame.\n",
            "*   **Robotics:**  If you're interested in building agents that control robots, focus on reinforcement learning, planning, computer vision, and sensor fusion.  Consider libraries like ROS (Robot Operating System).\n",
            "*   **Natural Language Processing:**  If you're interested in building agents that understand and generate human language, focus on NLP techniques like language modeling, text classification, and machine translation.  Consider libraries like Transformers (Hugging Face).\n",
            "*   **Multi-Agent Systems:** If you're interested in building systems where multiple agents interact, focus on game theory, mechanism design, and distributed AI.\n",
            "\n",
            "**7. Continuous Learning and Adaptation:**\n",
            "\n",
            "*   **Stay Up-to-Date:**  The field of AI is constantly evolving, so it's important to stay up-to-date with the latest research and technologies.\n",
            "*   **Be Open to New Ideas:**  Don't be afraid to try new approaches and experiment with different techniques.\n",
            "*   **Learn from Your Mistakes:**  Analyze your mistakes and learn from them.\n",
            "*   **Seek Feedback:**  Ask for feedback from other developers and researchers.\n",
            "\n",
            "By combining theoretical knowledge, practical experience, and continuous learning, you can significantly improve your skills in building AI agents. Remember to start with small projects, gradually increase the complexity, and stay curious! Good luck!\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Function to send a message and get a response\n",
        "def send_message(user_input: str):\n",
        "    \"\"\"\n",
        "    Send a message to the chatbot and display the response.\n",
        "    \"\"\"\n",
        "    print(f\"User: {user_input}\")\n",
        "\n",
        "    # Send the message through our graph\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            response = value[\"messages\"][-1].content\n",
        "            print(f\"Assistant: {response}\")\n",
        "    print(\"-\" * 50)  # Separator line\n",
        "\n",
        "# Test with a simple message\n",
        "send_message(\"How can I get better at building AI agents?\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "Pm3u7ZWPMJfs"
      },
      "source": [
        "## Step 10: Try More Examples! üéÆ\n",
        "\n",
        "Now that your chatbot is working, try asking it different questions. Each cell below contains a different example - run them to see how your chatbot responds!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKLflVyJMJft"
      },
      "outputs": [],
      "source": [
        "# Example 1: Ask about programming\n",
        "send_message(\"Can you explain what Python is in simple terms?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBS8u_UWMJft"
      },
      "outputs": [],
      "source": [
        "# Example 2: Ask for help with something\n",
        "send_message(\"I'm new to AI and chatbots. What should I learn next?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNL-kTS0MJft"
      },
      "outputs": [],
      "source": [
        "# Example 3: Try a creative question\n",
        "send_message(\"Write a short poem about robots learning to code\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "7m8Su8QEMJft"
      },
      "source": [
        "## Step 11: Interactive Chat Mode üí¨\n",
        "\n",
        "Want to have a longer conversation? The cell below creates an interactive chat where you can type messages and get responses.\n",
        "\n",
        "**Note**: This works best in Jupyter environments that support interactive input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqiUZtzXMJft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90aeff2-a08b-413c-8e86-aef124c51bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Welcome to your chatbot!\n",
            "Type your messages below. Type 'quit' to exit.\n",
            "==================================================\n",
            "\n",
            "You: what's the square root of 4\n",
            "Chatbot: The square root of 4 is 2.\n",
            "\n",
            "You: q\n",
            "Chatbot: Goodbye! Thanks for chatting! üëã\n"
          ]
        }
      ],
      "source": [
        "# Interactive chat session\n",
        "print(\"ü§ñ Welcome to your chatbot!\")\n",
        "print(\"Type your messages below. Type 'quit' to exit.\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input(\"\\nYou: \")\n",
        "\n",
        "        # Check if user wants to quit\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\", \"bye\"]:\n",
        "            print(\"Chatbot: Goodbye! Thanks for chatting! üëã\")\n",
        "            break\n",
        "\n",
        "        # Send message to chatbot\n",
        "        print(\"Chatbot: \", end=\"\")\n",
        "        for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "            for value in event.values():\n",
        "                response = value[\"messages\"][-1].content\n",
        "                print(response)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n\\nChatbot: Goodbye! Thanks for chatting! üëã\")\n",
        "except:\n",
        "    print(\"\\n\\nNote: Interactive input might not work in all environments.\")\n",
        "    print(\"If you see this message, try using the send_message() function instead!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "DbWBBu-UMJfu"
      },
      "source": [
        "üéì Congratulations! You've Built a Chatbot!\n",
        "\n",
        "What You've Learned:\n",
        "- ‚úÖ How to set up LangChain and LangGraph\n",
        "- ‚úÖ How to connect to Google's Gemini AI model\n",
        "- ‚úÖ How to define state management for conversations\n",
        "- ‚úÖ How to create a simple conversation flow\n",
        "- ‚úÖ How to test and interact with your chatbot\n",
        "\n",
        "What's Next?\n",
        "Here are some ideas to expand your chatbot:\n",
        "\n",
        "1. **Add Memory**: Make the chatbot remember conversation history across sessions\n",
        "2. **Add Tools**: Give your chatbot the ability to search the web, do calculations, etc.\n",
        "3. **Improve Responses**: Add system prompts to give your chatbot a personality\n",
        "4. **Add Error Handling**: Make your chatbot more robust with better error handling\n",
        "5. **Create a Web Interface**: Build a web app around your chatbot\n",
        "\n",
        "Resources to Continue Learning:\n",
        "- [LangChain Documentation](https://python.langchain.com/)\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- [Google AI Studio](https://aistudio.google.com/)\n",
        "\n",
        "Great job building your first AI chatbot! üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}